{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDFfromXML(path):\n",
    "\n",
    "    # create list of all columns from target schema\n",
    "    path_target = '../xml/Final_schema_XML.xml'\n",
    "    tree_target = ET.parse(path_target)\n",
    "    root_target = tree_target.getroot()\n",
    "    rows_target = []\n",
    "    columns = []\n",
    "    for species_target in root_target.iter('Species'):\n",
    "        for attr_target in species_target:\n",
    "            if attr_target not in columns:\n",
    "                columns.append(attr_target.tag)\n",
    "\n",
    "    \n",
    "    # To be deleted afterwards!\n",
    "    columns.append('Category')\n",
    "    \n",
    "    \n",
    "    # read in xml and create df\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    rows = []\n",
    "    for species in root.iter('Species'):\n",
    "\n",
    "        col_dict = {}\n",
    "        for col in columns:\n",
    "\n",
    "            for attr in species.iter(col):\n",
    "                if col in ['ID', 'Provenance', 'Scientific_Name', 'Category']:\n",
    "                    col_dict[col] = attr.text\n",
    "\n",
    "                else:\n",
    "                    temp_list = []\n",
    "                    for child in attr:\n",
    "                        temp_list.append(child.text)\n",
    "\n",
    "                    if len(temp_list) == 0:\n",
    "                        pass\n",
    "                    elif len(temp_list) == 1:\n",
    "                        col_dict[col] = temp_list[0]\n",
    "                    else:\n",
    "                        col_dict[col] = temp_list\n",
    "\n",
    "\n",
    "        rows.append(col_dict)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=columns)        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wd\n",
      "es\n",
      "np\n"
     ]
    }
   ],
   "source": [
    "path_IR_input = '../1_IdentityResolution/data/input/'\n",
    "\n",
    "dataset_dict = {}\n",
    "dataset_dict['wd'] = {}   #WikiData\n",
    "dataset_dict['es'] = {}   #EndangeroudSpecies\n",
    "dataset_dict['np'] = {}   #NationalParks\n",
    "\n",
    "dataset_dict['wd']['path'] = path_IR_input + 'wd_species.xml'   #WikiData\n",
    "dataset_dict['es']['path'] = path_IR_input + 'endangered_species.xml'   #EndangeroudSpecies\n",
    "dataset_dict['np']['path'] = path_IR_input + 'biodiversity.xml'   #NationalParks\n",
    "\n",
    "\n",
    "for dataset in dataset_dict.keys():\n",
    "    # read in xmls\n",
    "    print(dataset)\n",
    "\n",
    "    dataset_dict[dataset]['df'] = createDFfromXML(dataset_dict[dataset]['path'])\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wd = dataset_dict['wd']['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   ID                100000 non-null  object \n",
      " 1   Provenance        100000 non-null  object \n",
      " 2   Scientific_Name   99999 non-null   object \n",
      " 3   Common_Names      100000 non-null  object \n",
      " 4   Labels            0 non-null       float64\n",
      " 5   Where_Listed_l    0 non-null       float64\n",
      " 6   Different_From_l  346 non-null     object \n",
      " 7   Endemic_To_l      3960 non-null    object \n",
      " 8   Regions           0 non-null       float64\n",
      " 9   Region_Names      0 non-null       float64\n",
      " 10  Listing_Statuses  26637 non-null   object \n",
      " 11  Categories        0 non-null       float64\n",
      " 12  Orders            99403 non-null   object \n",
      " 13  Families          99738 non-null   object \n",
      " 14  States            0 non-null       float64\n",
      " 15  Category          90563 non-null   object \n",
      "dtypes: float64(6), object(10)\n",
      "memory usage: 12.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_wd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
