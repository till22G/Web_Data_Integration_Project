{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3407,
     "status": "ok",
     "timestamp": 1634799015702,
     "user": {
      "displayName": "Robert Blümel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16911302109144111457"
     },
     "user_tz": -120
    },
    "id": "6mIrdpsYRxXz",
    "outputId": "53e55b53-b424-41ef-eff0-34dbd55b7ae4"
   },
   "source": [
    "# Retrieval of species data for Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1634799020852,
     "user": {
      "displayName": "Robert Blümel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16911302109144111457"
     },
     "user_tz": -120
    },
    "id": "0JYNyWiCUQ-A"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.etree.ElementTree import Element, SubElement, Comment, tostring\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON, XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "### Namings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to files\n",
    "path_ids = '../data/wikidata/wd_identifier_list_1.csv'\n",
    "path_XML = '../xml/wd_species_target.xml'\n",
    "path_df  = '../data/wikidata/wd_species_df.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {\n",
    "   'resource': 'ID', \n",
    "   #'family',\n",
    "   #'class',\n",
    "   #'order',\n",
    "   'taxonName': {\n",
    "       'SubElement': 'Scientific_Names',\n",
    "       'SubSubElement': 'Scientific_Name'\n",
    "   },\n",
    "   'taxonCommonName': {\n",
    "       'SubElement': 'Common_Names',\n",
    "       'SubSubElement': 'Common_Name'\n",
    "   },\n",
    "   #'differentFrom',\n",
    "   #'endemicTo',\n",
    "   #'conservationStatus',\n",
    "   'resourceLabel': {\n",
    "       'SubElement': 'Labels',\n",
    "       'SubSubElement': 'Label'\n",
    "   }, \n",
    "   'familyLabel': {\n",
    "       'SubElement': 'Familys',\n",
    "       'SubSubElement': 'Family'\n",
    "   },\n",
    "   'classLabel': {\n",
    "       'SubElement': 'Categories',\n",
    "       'SubSubElement': 'Category'\n",
    "   },\n",
    "   'orderLabel': {\n",
    "       'SubElement': 'Orders',\n",
    "       'SubSubElement': 'Order'\n",
    "   },\n",
    "   'differentFromLabel': {\n",
    "       'SubElement': 'Different_Species',\n",
    "       'SubSubElement': 'Different_From'\n",
    "   },\n",
    "   'endemicToLabel': {\n",
    "       'SubElement': 'Endemic_Regions',\n",
    "       'SubSubElement': 'Endemic_To'\n",
    "   },\n",
    "   'conservationStatusLabel': 'Conservation_Status'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_query = \"\"\"\n",
    "\n",
    "SELECT ?resource\n",
    "\n",
    "WHERE {\n",
    "  ?resource wdt:P105 wd:Q7432.\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1634799907737,
     "user": {
      "displayName": "Robert Blümel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16911302109144111457"
     },
     "user_tz": -120
    },
    "id": "515YSjqHTt5O"
   },
   "outputs": [],
   "source": [
    "attribute_query = \"\"\"\n",
    "\n",
    "SELECT DISTINCT\n",
    "  ?resource\n",
    "  ?family\n",
    "  ?class\n",
    "  ?order\n",
    "  ?taxonName ?taxonCommonName \n",
    "  ?differentFrom ?endemicTo ?conservationStatus\n",
    "  \n",
    "  \n",
    "  ?resourceLabel\n",
    "  ?familyLabel\n",
    "  ?classLabel\n",
    "  ?orderLabel\n",
    "  ?differentFromLabel ?endemicToLabel ?conservationStatusLabel\n",
    "\n",
    "\n",
    "WHERE \n",
    "{{\n",
    "  \n",
    "  VALUES ?resource {{<{}>}}\n",
    "  \n",
    "  ## optional variables \n",
    "  \n",
    "    OPTIONAL {{?resource wdt:P171+ ?family.\n",
    "              ?family wdt:P105 wd:Q35409.\n",
    "           \n",
    "           OPTIONAL {{?family wdt:P171+ ?order.\n",
    "                     ?order wdt:P105 wd:Q36602.\n",
    "                    \n",
    "                    OPTIONAL {{?order wdt:P171+ ?class.\n",
    "                              ?class wdt:P105 wd:Q37517.}}}}}}\n",
    "  \n",
    "  # Taxon name\n",
    "  OPTIONAL {{?resource wdt:P225 ?taxonName.\n",
    "              FILTER (langMatches( lang(?taxonName), \"en\" ) )}}\n",
    "  # Taxon common name\n",
    "  OPTIONAL {{?resource wdt:P1843 ?taxonCommonName.\n",
    "              FILTER (langMatches( lang(?taxonCommonName), \"en\" ) )}}\n",
    "  # Different from \n",
    "  OPTIONAL {{?resource wdt:P1889 ?differentFrom.}}\n",
    "  # endemic to\n",
    "  OPTIONAL {{?resource wdt:P183 ?endemicTo.}}\n",
    "  # conservation status \n",
    "  OPTIONAL {{?resource wdt:P141 ?conservationStatus.}}\n",
    "  \n",
    "  SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "}}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runQuery(query, format):\n",
    "\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(format) \n",
    "\n",
    "    try :\n",
    "        results = sparql.query().convert()\n",
    "        #print('Nr. of results: ', len(results['results']['bindings']))\n",
    "    except :\n",
    "        deal_with_the_exception()\n",
    "\n",
    "    return results\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectAndSaveIdentifiers():\n",
    "    \n",
    "    # run sparql query\n",
    "    species_results = runQuery(species_query, JSON)\n",
    "    \n",
    "    # retrieve identifier\n",
    "    identifier_list = []\n",
    "    for identifier in species_results['results']['bindings']:\n",
    "        identifier_list.append(identifier['resource']['value'])\n",
    "\n",
    "    # write down list as csv file\n",
    "    df_identifier_list = pd.DataFrame(identifier_list, columns = ['resources'])\n",
    "    df_identifier_list.to_csv(path_ids,  index = False)\n",
    "        \n",
    "    return identifier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiateDataframe(identifier_list):\n",
    "    # test whether result collection dataframe already defined, \n",
    "    # else retrieve columns from query and instantiate dataframe \n",
    "    try: \n",
    "        df_results = pd.read_csv(path_df)\n",
    "\n",
    "    except:\n",
    "        results = runQuery(attribute_query.format(identifier_list[0]), JSON)\n",
    "        columns = results['head']['vars']\n",
    "        df_results = pd.DataFrame(columns = columns)\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertResultsToDict(results):\n",
    "\n",
    "    # create new results dict to collect and combine attributes\n",
    "    r_dict = {}\n",
    "\n",
    "    # loop through different result sets for this resource\n",
    "    for result_set in results['results']['bindings']:\n",
    "\n",
    "\n",
    "        # loop through all attributes for this result set\n",
    "        for attribute in result_set:\n",
    "            #print(attribute, result_set[attribute]['value'])\n",
    "\n",
    "            # assign new value (in lower case)\n",
    "            new_value = result_set[attribute]['value'].lower()\n",
    "\n",
    "            # if attribute not yet seen, add to dict\n",
    "            if attribute not in r_dict.keys():\n",
    "                # assign string to attribute \n",
    "                r_dict[attribute] = new_value\n",
    "\n",
    "            # if attribute already in dict\n",
    "            else:\n",
    "                old_value = r_dict[attribute]\n",
    "\n",
    "                # if value is single string, create list of old and new value and assign back\n",
    "                if type(old_value) == str and old_value != new_value:\n",
    "                    l = []\n",
    "                    l.append(old_value)\n",
    "                    l.append(new_value)\n",
    "                    r_dict[attribute] = l\n",
    "\n",
    "                # if value is list, append new_value\n",
    "                elif type(old_value) == list and new_value not in old_value:\n",
    "                    old_value.append(new_value)\n",
    "\n",
    "                #else:\n",
    "                #    raise Exception('Merging of results in JSON: Formating of dictionary values wrong')\n",
    "\n",
    "    return r_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendDataframe(r_dict, df_results):\n",
    "    \n",
    "    # append new entry to backup dataframe            \n",
    "    df_new_entry = pd.DataFrame.from_dict([r_dict])\n",
    "    df_results = pd.concat([df_results, df_new_entry])\n",
    "\n",
    "    # save dataframe\n",
    "    df_results.to_csv(path_df, index=False)\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendXML(root, r_dict, mapping_dict):\n",
    "\n",
    "    # for each new resource, create new species\n",
    "    new_element = SubElement(root, 'Species')\n",
    "\n",
    "    # loop through dictionary\n",
    "    for key in r_dict:\n",
    "        if key in mapping_dict.keys():\n",
    "\n",
    "            # try whether nested elements are provided by the mapping dictionary\n",
    "            try:\n",
    "                new_subelement = SubElement(new_element, mapping_dict[key]['SubElement'])\n",
    "\n",
    "                # differentiate bewteen list elements and simple strings\n",
    "                if type(r_dict[key]) == str:\n",
    "                    new_subsubelement = SubElement(new_element, mapping_dict[key]['SubSubElement']).text = r_dict[key]\n",
    "                else:    \n",
    "                    for value in r_dict[key]:\n",
    "                        new_subsubelement = SubElement(new_element, mapping_dict[key]['SubSubElement']).text = value\n",
    "\n",
    "            # else only use the direct term - applies if no list of elements expected (ID, conservation status, etc--)\n",
    "            except:    \n",
    "                new_subelement = SubElement(new_element, mapping_dict[key]).text = r_dict[key]\n",
    "                \n",
    "                \n",
    "    # writing XML file out\n",
    "    tree = ET.ElementTree(root_target)\n",
    "    tree.write(path_XML)\n",
    "\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval & Processing\n",
    "\n",
    "### Retrieval of  list of species\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1634810458677,
     "user": {
      "displayName": "Robert Blümel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16911302109144111457"
     },
     "user_tz": -120
    },
    "id": "2eZcvX9DSyZB",
    "outputId": "99fada0e-99dd-4b38-aecc-baed2bf2e007"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# try reading in list of identifiers\n",
    "try:\n",
    "    retrieved_identifiers = list(pd.read_csv(path_ids)['resources'])\n",
    "\n",
    "    # if list longer 100, consider as full list, not mock, example\n",
    "    if len(retrieved_identifiers) > 100:\n",
    "        identifier_list = retrieved_identifiers\n",
    "    else:\n",
    "        identifier_list = collectAndSaveIdentifiers()\n",
    "except:\n",
    "    identifier_list = collectAndSaveIdentifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(identifier_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval of attributes for each species & processing to Dataframe and XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to read in root, otherwise create\n",
    "try:\n",
    "    tree = ET.parse(path_XML)\n",
    "    root_target = tree.getroot()\n",
    "except:\n",
    "    ## creation of new root \n",
    "    root_target = ET.Element('animals_and_plants')\n",
    "    \n",
    "# Datagrame    \n",
    "df_results = instantiateDataframe(identifier_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set offset based on amount of already queried species\n",
    "offset = len(df_results)\n",
    "\n",
    "for identifier in identifier_list[offset:]:\n",
    "    \n",
    "    #retrieval of attributes per species\n",
    "    results = runQuery(attribute_query.format(identifier), JSON)\n",
    "    \n",
    "    # convert and merge results in dict\n",
    "    r_dict = convertResultsToDict(results)\n",
    "    \n",
    "    # append new entries\n",
    "    df_results = appendDataframe(r_dict, df_results)\n",
    "\n",
    "    # append xml file\n",
    "    root_target = appendXML(root_target, r_dict, mapping_dict)\n",
    "    \n",
    "    time.sleep(60)\n",
    "    \n",
    "ET.dump(root_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOBldVPNjlrKvsAKMHr1HnB",
   "collapsed_sections": [],
   "name": "wd_species.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
